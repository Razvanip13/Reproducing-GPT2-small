# Reproducing-GPT2-mini

<p align="center">
    <img src="assets/joke.png" alt="trainAnLLM" width="300" height="350">
    <img src="assets/understand.png" alt="understand" width="400" height="350">
</p>

Large Language Models (LLMs) can seem like dark magic. The idea of training a model like GPT2 might feel overwhelming, especially with all the hype and complexity surrounding the newest enterprise models. However, the best way to understand LLMs is to build one yourself.

This project is my own reimplementation of Andrej Karpathyâ€™s work, breaking down the concepts into something approachable and practical for myself. By recreating GPT-2 step by step, I aim to gain a deeper understanding of how these models function under the hood.

## GPT2

## FineWeb 

## HellaSwag

## Pre-training

## Post-training

## Requirements 

